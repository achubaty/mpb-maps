---
title: "Mountain pine beetle outbreak maps"
author:
- name: "Alex M. Chubaty"
  affiliaton: |
    Canadian Forest Service
    Pacific Forestry Centre  
    506 Burnside Road W  
    Victoria, BC V8Z 1M5
    +1.250.298.2347
    alexander.chubaty@canada.ca
- name: "Eliot J. B. McIntire"
  affiliaton: |
    Canadian Forest Service
    Pacific Forestry Centre  
    506 Burnside Road W  
    Victoria, BC V8Z 1M5
    +1.250.298.2374
    eliot.mcintire@canada.ca
output:
  pdf_document:
    toc: yes
    toc_depth: 3
date: "December 16, 2016"
---

```{r setup, include=FALSE, message=FALSE}
## determine OS and whether we are on a CFS machine
._CFS_. <- grepl("W-VIC", Sys.info()[["nodename"]])
._OS_. <- Sys.info()[["sysname"]]
._USER_. <- Sys.info()[["user"]]

## set R and knitr options
if (isTRUE(._CFS_.)) {
  options(repos = c(CRAN = "https://cran.rstudio.com/",
                    NRCRAN = "http://132.156.149.95"))
} else {
  options(repos = c(CRAN = "https://cran.rstudio.com/"))
}

knitr::opts_chunk$set(cache = TRUE, cache.path = "cache/", echo = FALSE,
                      message = FALSE, warning = FALSE, fig.path = "figures/")

## attach packages
suppressPackageStartupMessages({
  library(data.table)
  library(devtools)
  library(digest)
  library(magrittr)
  library(maps)
  library(mapdata)
  library(maptools)
  library(plotKML)
  library(raster)
  library(rgdal)
  library(rgeos)
  library(rts)
  library(shapefiles)
  library(snowfall)
  library(spatstat)
  library(RColorBrewer)
})

## additional helper functions
source_url("https://raw.githubusercontent.com/achubaty/r-tools/master/download-data.R")
source_url("https://raw.githubusercontent.com/achubaty/r-tools/master/rdata-objects.R")
source_url("https://raw.githubusercontent.com/achubaty/r-tools/master/sysmem.R")

#' manual garbage collection to free recently unallocated memory 
.cleanup <- function() {
  for (i in 1:10) gc()
}

#' readOGR without having ]to manually change working directory
getOGR <- function(layer, dir) {
  orig.dir <- getwd()
  setwd(dir); on.exit(setwd(orig.dir))
  out <- readOGR(dsn = ".", layer = layer)
  return(out)
}

## set work dirs based on computer used
if (._USER_. == "achubaty") {
  if (._OS_. == "Darwin") {
    maps.dir <- "~/Documents/data/maps"
    work.dir <- "~/Documents/GitHub/MPB/mpb-maps"
  } else if (._OS_. == "Linux") {
    if (isTRUE(._CFS_.)) {
      maps.dir <- "/mnt/A105388/shared/data"
    } else {
      maps.dir <- "~/Documents/Data/shared"
    }
    work.dir <- "~/Documents/GitHub/MPB/mpb-maps"
  } else if (._OS_. == "Windows") {
    maps.dir <- "//W-VIC-A105388/shared/data"
    work.dir <- "~/GitHub/MPB/mpb-maps"
  } else {
    stop("Which operating system are you using?")
  }
}
setwd(work.dir)
rdata.path <- file.path(maps.dir, "MPB", "Rmaps")
fig.path <- file.path(work.dir, "figures")
if (!dir.exists(fig.path)) dir.create(fig.path)

stopifnot(all(dir.exists(c(fig.path, maps.dir, rdata.path, work.dir))))

## additional options
._NUM_CPUS_. <- parallel::detectCores() / 2 ## max cpus to use

# options below only need to be changed if you want to reprocess the data
# - e.g., you get new MPB map data
# - e.g., you want to change the resolution/extent/etc. of the maps
#        (before rerunning just to change res, can you `clip` out a subset?)
#
._MAPS_USERAW_. <- FALSE  ## read in raw maps from data
._MAPS_REPROJ_. <- FALSE  ## reproject raw maps to `boreal`
._MAPS_MKRSTR_. <- FALSE  ## convert the maps to rasters

# map extent obtained using `locator(2)` on 'west.boreal' map
._EXT_MAPS_. <- extent(x = -1027658, xmax = 320751.9, ymin = 5108872, ymax = 6163350)

._RES_MAPS_. <- 1000       # map resolution, in metres
```

\newpage

## Overview of MPB map data

Descriptions of:

- data sources
- data collected
- etc.

## Processing the MPB map data

### Importing map data

#### MPB `SpatialPoints` data

```{r import-maps-points}
if (isTRUE(._MAPS_USERAW_.)) {
  ### Read in raw maps, and save them as individual files 
  ### - this may take a while...grab a coffee or something 
  sfInit(cpus = ._NUM_CPUS_., parallel = TRUE) 
    sfLibrary(rgdal) 
    sfLibrary(sp) 
       
    ### AB points maps 
    ab.pnts.files <- dir(path = file.path(maps.dir, "MPB", "ab_mpb"), pattern = "spot") 
    ab.pnts.dir.shp <- unique(sapply(strsplit(ab.pnts.files, "\\."), function(x) x[[1]])) 
    ab.pnts <- sfClusterApplyLB(ab.pnts.dir.shp, fun = getOGR, dir = file.path(maps.dir, "MPB", "ab_mpb")) %>% 
      setNames(substr(sapply(strsplit(ab.pnts.dir.shp, "_"), function(x) x[[3]]), 1, 4)) %>%
      lapply(., function(x) {
        names(x) <- toupper(names(x))
        return(x)
      })
     
    ### BC points maps 
    bc.pnts.files <- dir(path = file.path(maps.dir, "MPB", "province_BC"), pattern = "spot") 
    bc.pnts.dir.shp <- unique(sapply(strsplit(bc.pnts.files, "\\."), function(x) x[[1]])) 
    omit <- which(match(bc.pnts.dir.shp, "ibm_spot_data_northernpoints_removed", nomatch = 0) == 1) 
    if (length(omit) > 0) bc.pnts.dir.shp <- bc.pnts.dir.shp[-omit] 
    bc.pnts <- sfClusterApplyLB(bc.pnts.dir.shp, fun = getOGR, dir = file.path(maps.dir, "MPB", "province_BC")) %>% 
      setNames(sapply(strsplit(bc.pnts.dir.shp, "_"), function(x) x[[3]])) %>%
        lapply(., function(x) {
        names(x) <- toupper(names(x))
        return(x)
      })
    
    # save for later use 
    saveObjects(c("ab.pnts", "bc.pnts"), rdata.path) 
   
    # clean up workspace 
    rm(ab.pnts, ab.pnts.dir.shp, ab.pnts.files,
       bc.pnts, bc.pnts.dir.shp, bc.pnts.files, omit)
  sfStop()

  .cleanup()
}
```

#### MPB `SpatialPolygons` data

```{r import-maps-polygons}
if (isTRUE(._MAPS_USERAW_.)) {
  sfInit(cpus = ._NUM_CPUS_., parallel = TRUE) 
    sfLibrary(rgdal) 
    sfLibrary(sp) 
     
    ### AB poly maps 
    ab.poly.files <- dir(path = file.path(maps.dir, "MPB", "ab_mpb"), pattern = "poly") 
    ab.poly.dir.shp <- unique(sapply(strsplit(ab.poly.files, "\\."), function(x) x[[1]])) 
    ab.poly <- sfClusterApplyLB(ab.poly.dir.shp, fun = getOGR, dir = file.path(maps.dir, "MPB", "ab_mpb")) %>% 
      setNames(substr(sapply(strsplit(ab.poly.dir.shp, "_"), function(x) x[[3]]), 1, 4)) 
     
    # save these new map objects for later use 
    saveObjects("ab.poly", rdata.path) 
   
    ### BC poly maps 
    bc.poly.files <- dir(path = file.path(maps.dir, "MPB", "province_BC"), pattern = "poly") 
    bc.poly.dir.shp <- unique(sapply(strsplit(bc.poly.files, "\\."), function(x) x[[1]])) 
    bc.poly <- sfClusterApplyLB(bc.poly.dir.shp, fun = getOGR, dir = file.path(maps.dir, "MPB", "province_BC")) %>% 
      setNames(sapply(strsplit(bc.poly.dir.shp, "_"), function(x) x[[3]]))
    
    # save these new map objects for later use 
    saveObjects("bc.poly", rdata.path) 
     
    # clean up workspace 
    rm(ab.poly, ab.poly.dir.shp, ab.poly.files) 
    rm(bc.poly, bc.poly.dir.shp, bc.poly.files) 
  sfStop()
  
  .cleanup()
}
```

#### Canadian administrative boundaries

```{r can_adm}
if (isTRUE(._MAPS_USERAW_.)) {
  adm.path <- file.path(maps.dir, "CAN_adm")
  for (s in 0:3) {
    assign(paste0("CAN_adm", s),
           raster::getData('GADM', path = adm.path, country = "Canada", level = s),
           envir = .GlobalEnv)
    save(list = paste0("CAN_adm", s), file = file.path(rdata.path, paste0("CAN_adm", s, ".Rdata")))
  }
}
```

#### Canadian boreal forest maps

```{r import-maps-boreal}
if (isTRUE(._MAPS_USERAW_.)) {
  f <- file.path(maps.dir, "boreal", "NABoreal.shp")
  if (!file.exists(f)) {
    url <- "http://cfs.nrcan.gc.ca/common/boreal.zip"
    dl.data(url, dest = maps.dir, unzip = TRUE)
  }
  
  files <- file.path(rdata.path, c("boreal.RData", "boreal.can.RData"))
  if (all(file.exists(files))) {
    lapply(files, load, envir = .GlobalEnv)
  } else {
    boreal <- getOGR("NABoreal", file.path(maps.dir, "boreal"))
    boreal.can <- boreal[boreal$COUNTRY == "CANADA",]
  }
  crs.boreal <- CRS(proj4string(boreal))
  rm(f, files)
  
  west.provs <- c("Alberta", "British Columbia", "Saskatchewan")
  canada1.west <- CAN_adm1[CAN_adm1$NAME_1 %in% west.provs, ]
  canada2.west <- CAN_adm2[CAN_adm2$NAME_1 %in% west.provs, ]

  west.boreal <- spTransform(canada1.west, CRSobj =  crs.boreal)
  west2.boreal <- spTransform(canada2.west, CRSobj =  crs.boreal)
  canada1.boreal <- spTransform(CAN_adm1, CRSobj =  crs.boreal)
  canada2.boreal <- spTransform(CAN_adm2, CRSobj =  crs.boreal)
  boreal.west <- intersect(boreal, west.boreal)
  
  ### Save these new map objects for later use
  objects2save <- c("boreal", "boreal.can", "boreal.west",
                    "canada1.west", "canada2.west",
                    "canada1.boreal", "canada2.boreal",
                    "west.boreal", "west2.boreal")
  saveObjects(objects2save, rdata.path)
  rm(list = objects2save)
  rm(objects2save)
  .cleanup()
}
```

### Reproject MPB maps to `crs.boreal`

#### MPB `SpatialPoints` data

```{r reproject-maps-points}
if (isTRUE(._MAPS_REPROJ_.)) {
  if (!exists("crs.boreal")) {
    loadObjects("boreal", rdata.path)
    crs.boreal <- CRS(proj4string(boreal))
    rm(boreal)
  }
  
  loadObjects(c("ab.pnts", "bc.pnts"), rdata.path)
  
  ### REPROJECT AB, BC SO THEY ARE BOTH IN THE `boreal` PROJECTION
  sfInit(cpus = ._NUM_CPUS_., parallel = TRUE)
    sfLibrary(rgdal)
    
    ab.pnts.boreal <- sfClusterApplyLB(ab.pnts, spTransform, crs.boreal) %>%
      setNames(names(ab.pnts))
    bc.pnts.boreal <- sfClusterApplyLB(bc.pnts, spTransform, crs.boreal) %>% 
      setNames(names(bc.pnts))

    # save these new map objects for later use
    saveObjects(c("ab.pnts.boreal", "bc.pnts.boreal"), rdata.path)
  sfStop()
  .cleanup()

  ### MERGE AB AND BC POINTS
  wh.ab <- na.omit(match(names(bc.pnts.boreal), names(ab.pnts.boreal)))
  wh.bc <- na.omit(match(substr(names(ab.pnts.boreal), 1, 4), names(bc.pnts.boreal)))
  
  sfInit(cpus = ._NUM_CPUS_., parallel = TRUE)
    sfLibrary(maptools)
    sfLibrary(sp)
    sfExport("ab.pnts.boreal", "bc.pnts.boreal", "crs.boreal", "wh.ab", "wh.bc")  
    
    bcab.pnts.boreal <- sfClusterApplyLB(1:length(wh.ab), function(x) {
      out <- spRbind(bc.pnts.boreal[[wh.bc[x]]][, "NUM_TREES"], ab.pnts.boreal[[wh.ab[x]]][, "NUM_TREES"])
      return(out)
    }) %>%
      sfClusterApplyLB(., function(x) {
      proj4string(x) <- crs.boreal
      return(x)
    }) %>%
      setNames(names(bc.pnts.boreal)[wh.bc])
    
    saveObjects("bcab.pnts.boreal", rdata.path)
  sfStop()
  .cleanup()
  
  ## cleanup workspace
  rm(ab.pnts, ab.pnts.boreal, bc.pnts, bc.pnts.boreal, bcab.pnts.boreal, wh.ab, wh.bc)
  .cleanup()
}
```

#### MPB `SpatialPolygons` data

```{r reproject-maps-polygons}
if (isTRUE(._MAPS_REPROJ_.)) {
  if (!exists("crs.boreal")) {
    loadObjects("boreal", rdata.path)
    crs.boreal <- CRS(proj4string(boreal))
    rm(boreal)
  }
  
  loadObjects(c("ab.poly", "bc.poly"), rdata.path)
  
  ### REPROJECT AB AND BC SO THEY ARE BOTH IN THE `boreal` PROJECTION
  sfInit(cpus = ._NUM_CPUS_., parallel = TRUE)
    sfLibrary(magrittr)
    sfLibrary(rgdal)
    sfLibrary(rgeos)
    sfExport("crs.boreal")
    
    ab.poly.boreal <- sfClusterApplyLB(ab.poly, function(x) {
      spTransform(x, crs.boreal) %>% 
        gBuffer(., byid = TRUE, width = 0)
    }) %>% 
      setNames(names(ab.poly))
    stopifnot(all(sapply(ab.poly.boreal, gIsValid)))
    saveObjects("ab.poly.boreal", rdata.path)
    rm(ab.poly)
  
    bc.poly.boreal <- sfClusterApplyLB(bc.poly, function(x) {
      spTransform(x, crs.boreal) %>% 
        gBuffer(., byid = TRUE, width = 0)
    }) %>% 
      setNames(names(bc.poly))
    stopifnot(all(sapply(bc.poly.boreal, gIsValid)))
    saveObjects("bc.poly.boreal", rdata.path)
    rm(bc.poly)
  sfStop()
  .cleanup()
  
  ### MERGE AB AND BC POLYGONS
  wh.ab <- na.omit(match(names(bc.poly.boreal), names(ab.poly.boreal)))
  wh.bc <- na.omit(match(substr(names(ab.poly.boreal), 1, 4), names(bc.poly.boreal)))
  
  sfInit(cpus = ._NUM_CPUS_., parallel = TRUE)
    sfLibrary(sp)
    sfLibrary(raster)
    sfExport("ab.poly.boreal", "bc.poly.boreal", "crs.boreal", "wh.ab", "wh.bc")  
    
    bcab.pnts.boreal <- sfClusterApplyLB(1:length(wh.ab), function(x) {
      union(bc.poly.boreal[[wh.bc[x]]], ab.poly.boreal[[wh.ab[x]]])
    }) %>%
      sfClusterApplyLB(., function(x) {
      proj4string(x) <- crs.boreal
      return(x)
    }) %>%
      setNames(names(bc.pnts.boreal)[wh.bc])
    
    saveObjects("bcab.pnts.boreal", rdata.path)
  sfStop()
  .cleanup()
}
```

### Rasterize MPB maps

#### Canadian boreal forest maps

```{r rasterize-maps-boreal}
if (isTRUE(._MAPS_MKRSTR_.)) {
  loadObjects("west.boreal", rdata.path)
  
  west.empty.raster <- raster(extent(west.boreal), resolution = ._RES_MAPS_.)
  west.boreal.raster <- suppressWarnings(
    rasterize(west.boreal, west.empty.raster,
              filename = file.path(rdata.path, "west_boreal.grd"),
              overwrite = TRUE)
  )
  
  saveObjects("west.boreal.raster", rdata.path)
  
  ## cleanup workspace
  rm(west.boreal, west.boreal.raster, west.empty.raster)
  .cleanup()
}
```

#### MPB `SpatialPoints` data

```{r rasterize-maps-points}
if (isTRUE(._MAPS_MKRSTR_.)) {
  loadObjects(c("ab.pnts.boreal", "bc.pnts.boreal", "bcab.pnts.boreal"), rdata.path)
  suppressWarnings(loadObjects("west.boreal.raster", rdata.path))
  
  rasterize.mpb <- function(x,...) {
    rasterize(x = x, y = west.boreal.raster,
              field = as.numeric(x@data$NUM_TREES),
              fun = "sum", overwrite = TRUE, ...)
  }
  
  sfInit(cpus = ._NUM_CPUS_., parallel = TRUE)
    sfLibrary(raster)
    sfExport("west.boreal.raster")
    
    ab.pnts.boreal.raster.stack <- stack(sfClusterApplyLB(ab.pnts.boreal, rasterize.mpb)) %>%
      setNames(names(ab.pnts.boreal))
    writeRaster(ab.pnts.boreal.raster.stack, file.path(rdata.path, "ab_pnts_boreal.grd"), overwrite = TRUE)
    saveObjects("ab.pnts.boreal.raster.stack", rdata.path)
    rm(ab.pnts.boreal, ab.pnts.boreal.raster.stack)
    .cleanup()
  
    bc.pnts.boreal.raster.stack <- stack(sfClusterApplyLB(bc.pnts.boreal, rasterize.mpb)) %>% 
      setNames(names(bc.pnts.boreal))
    writeRaster(bc.pnts.boreal.raster.stack, file.path(rdata.path, "bc_pnts_boreal.grd"), overwrite = TRUE)
    saveObjects("bc.pnts.boreal.raster.stack", rdata.path)
    rm(bc.pnts.boreal, bc.pnts.boreal.raster.stack)
    .cleanup()
    
    bcab.pnts.boreal.raster.stack <- stack(sfClusterApplyLB(bcab.pnts.boreal, rasterize.mpb)) %>%
      set_names(names(bcab.pnts.boreal))
    writeRaster(bcab.pnts.boreal.raster.stack, file.path(rdata.path, "bcab_pnts_boreal.grd"), overwrite = TRUE)
    saveObjects("bcab.pnts.boreal.raster.stack", rdata.path)
    rm(bcab.pnts.boreal, bcab.pnts.boreal.raster.stack)
    .cleanup()
  sfStop()

  ## cleanup workspace
  rm(west.boreal.raster)
  .cleanup()
}
```

#### MPB `SpatialPolygons` data

```{r rasterize-maps-polygons}
if (isTRUE(._MAPS_MKRSTR_.)) {
  loadObjects(c("ab.poly.boreal", "bc.poly.boreal"), rdata.path)
  suppressWarnings(loadObjects("west.boreal.raster", rdata.path))
  
  ### we arbitrarily picked 1000 trees per 1ha
  ###   This NEEDS to be revisited.
  change.res <- function(x, y = west.boreal.raster, field = 1000, fun = "last", ...) {
    rasterize(x = x, y = y, field = field, fun = fun, ...)
  }
  
  sfInit(cpus = ._NUM_CPUS_., parallel = TRUE)
    sfLibrary(raster)
    sfExport("west.boreal.raster")
    
    ab.poly.boreal.raster.stack <- sfClusterApplyLB(ab.poly.boreal, change.res) %>%
      stack() %>%
      setNames(ab.poly.boreal)
    ## several rasters have no values because they were in southern Alberta
    notNAs <- which(sapply(1:nlayers(ab.poly.boreal.raster.stack), function(x) {
      unique(!is.na(which.min(ab.poly.boreal.raster.stack[[x]])))
    }))
    ab.poly.boreal.raster.stack <- ab.poly.boreal.raster.stack[[notNAs]] %>% 
      setNames(unlist(strsplit(names(ab.poly.boreal), "poly"))[notNAs])
    writeRaster(ab.poly.boreal.raster.stack,
                filename = file.path(rdata.path, "ab_poly_boreal.grd"), overwrite = TRUE)
    saveObjects("ab.poly.boreal.raster.stack", rdata.path)
      
    bc.poly.boreal.raster.stack <- sfClusterApplyLB(bc.poly.boreal, change.res) %>%
      stack() %>%
      setNames(bc.poly.boreal)
    writeRaster(bc.poly.boreal.raster.stack,
                filename = file.path(rdata.path, "bc_poly_boreal.grd"), overwrite = TRUE)
    saveObjects("bc.poly.boreal.raster.stack", rdata.path)
    rm(change.res, notNAs)
  sfStop()
  rm("ab.poly.boreal", "bc.poly.boreal")
  .cleanup()
  
  ### merge ab and bc polygon rasters
  ab.poly.boreal.raster.unstack <- unstack(ab.poly.boreal.raster.stack)
  bc.poly.boreal.raster.unstack <- unstack(bc.poly.boreal.raster.stack)
  
  bcab.poly.boreal.raster.unstack <- bc.poly.boreal.raster.unstack
  
  wh.ab <- na.omit(match(names(bc.poly.boreal.raster.stack), names(ab.poly.boreal.raster.stack)))
  wh.bc <- na.omit(match(names(ab.poly.boreal.raster.stack), names(bc.poly.boreal.raster.stack)))
  bcab.poly.boreal.raster.unstack[wh.bc] <- lapply(1:length(wh.bc), function(x) {
    out <- merge(bc.poly.boreal.raster.unstack[[wh.bc[x]]],
                 ab.poly.boreal.raster.unstack[[wh.ab[x]]])
    return(out)
  })
  bcab.poly.boreal.raster.stack <- stack(bcab.poly.boreal.raster.unstack) %>%
    setNames(bc.poly.boreal.raster.stack)
  
  writeRaster(bcab.poly.boreal.raster.stack,
              filename = file.path(rdata.path, "bcab_poly_boreal.grd"), overwrite = TRUE)
  saveObjects("bcab.poly.boreal.raster.stack", rdata.path)
  
  ## cleanup workspace
  objects2rm <- c("ab.poly.boreal.raster.stack", "ab.poly.boreal.raster.unstack",
                  "bc.poly.boreal.raster.stack", "bc.poly.boreal.raster.unstack",
                  "bcab.poly.boreal.raster.stack", "bcab.poly.boreal.raster.unstack", 
                  "west.boreal.raster", "wh.ab", "wh.bc")
  rm(list = objects2rm)
  rm(objects2rm)
  .cleanup()
}
```

### Combine all MPB maps

```{r combine-maps-all}
if (isTRUE(._MAPS_MKRSTR_.)) {
  if (!exists("crs.boreal")) {
    loadObjects("boreal", rdata.path)
    crs.boreal <- CRS(proj4string(boreal))
    rm(boreal)
  }

  ### combine bcab points and poly rasters
  loadObjects(c("bcab.pnts.boreal.raster.stack", "bcab.poly.boreal.raster.stack"), rdata.path)
  
  wh.pnts <- na.omit(match(names(bcab.poly.boreal.raster.stack), names(bcab.pnts.boreal.raster.stack)))
  wh.poly <- na.omit(match(names(bcab.pnts.boreal.raster.stack), names(bcab.poly.boreal.raster.stack)))
  
  all <- list()
  j <- 0
  for (i in 1:nlayers(bcab.poly.boreal.raster.stack)) {
    if (any(names(bcab.poly.boreal.raster.stack)[i] == names(bcab.pnts.boreal.raster.stack))) {
      j <- j + 1
      if (any(is.finite(cellStats(bcab.poly.boreal.raster.stack[[i]], "range")))) {
        all[[i]] <- merge(bcab.pnts.boreal.raster.stack[[wh.pnts[j]]],
                          bcab.poly.boreal.raster.stack[[wh.poly[j]]])
      } else {
        all[[i]] <- bcab.pnts.boreal.raster.stack[[wh.pnts[j]]]
      }
    } else {
      all[[i]] <- bcab.poly.boreal.raster.stack[[i]]
    }
  }
  
  all <- lapply(all, function(x) {
    x[is.na(x)] <- 0; return(x)
  }) %>% lapply(., function(x) {
    x[x > 0] <- log(x[x > 0]) + 10
    return(x)
  }) %>% setNames(substr(names(bcab.poly.boreal.raster.stack), 2, 5))
  
  bcab.all.boreal.raster.stack <- stack(all) %>%
    setNames(substr(names(bcab.poly.boreal.raster.stack), 2, 5))
  bcab.all.boreal.raster.brick <- brick(bcab.all.boreal.raster.stack,
                                        filename = file.path(rdata.path, "bcab.all.boreal.raster.brick.grd"),
                                        overwrite = TRUE) %>%
    setNames(substr(names(bcab.poly.boreal.raster.stack), 2, 5))
    
  bcab.all.boreal.raster.stack <- writeRaster(bcab.all.boreal.raster.stack,
                                              filename = file.path(rdata.path, "bcab.all.boreal.raster.stack.grd"),
                                              overwrite = TRUE)
    
  saveObjects(c("bcab.all.boreal.raster.brick", "bcab.all.boreal.raster.stack"), rdata.path)
  
  ## cleanup workspace
  rm(all, bcab.all.boreal.raster.brick, bcab.all.boreal.raster.stack,
     bcab.pnts.boreal.raster.stack, bcab.poly.boreal.raster.stack,
     wh.pnts, wh.poly)
  .cleanup()
}
```

## Plotting maps

### Boreal forest maps

**The Canadian boreal forest:**

```{r plot-canada.boreal, fig.height=12, fig.width=16}
loadObjects(c("boreal.can", "canada1.boreal"), rdata.path)
darkgreen <- col2rgb("darkgreen") / 255
col.bor <- rgb(darkgreen[1], darkgreen[2], darkgreen[3], alpha = 0.5)
rm(darkgreen)

plot(canada1.boreal)
plot(boreal.can, col = col.bor, add = TRUE)

png(file.path(fig.path, "boreal.can.png"), type = "cairo", width = 1600, height = 1200)
plot(canada1.boreal)
plot(boreal.can, col = col.bor, add = TRUE)
dev.off()

rm(boreal.can)
```

**The western Canadian boreal forest:**

```{r plot-western.boreal, fig.height=12, fig.width=16}
loadObjects(c("boreal.west", "west.boreal"), rdata.path)
darkgreen <- col2rgb("darkgreen")/255
col.bor <- rgb(darkgreen[1], darkgreen[2], darkgreen[3], alpha = 0.5)
rm(darkgreen)

plot(west.boreal)
plot(boreal.west, col = col.bor, add = TRUE)

png(file.path(fig.path, "boreal.west.png"), type = "cairo", width = 1600, height = 1200)
plot(west.boreal)
plot(boreal.west, col = col.bor, add = TRUE)
dev.off()

rm(boreal.west, west.boreal)
```

### MPB in western Canada

#### MPB `SpatialPoints` data

```{r plot-mpb.western.boreal.points, fig.height=10, fig.width=12, eval=FALSE}
loadObjects(c("ab.pnts.boreal", "bc.pnts.boreal", "west.boreal"), rdata.path)

plot(west.boreal)
colours <- brewer.pal(n = 9, name = "YlOrRd")
for (i in names(ab.pnts.boreal)) {
  points(ab.pnts.boreal[[i]], pch = ".", col = colours)
}
for (i in names(bc.pnts.boreal)) {
  points(bc.pnts.boreal[[i]], pch = ".", col = colours)
}

rm(ab.pnts.boreal, bc.pnts.boreal, west.boreal)
```

#### MPB `SpatialPolygons` data

```{r plot-mpb.western.boreal.polygons, fig.height=10, fig.width=12, eval=FALSE}
loadObjects(c("ab.poly.boreal", "bc.poly.boreal", "west.boreal"), rdata.path)
plot(west.boreal)
colours <- brewer.pal(n = 9, name = "YlOrRd")
for (i in names(bc.poly.boreal)) {
  plot(ab.poly.boreal[[i]], col = colours, add = TRUE)
}
for (i in names(bc.poly.boreal)) {
  plot(bc.poly.boreal[[i]], col = colours, add = TRUE)
}
rm(ab.poly.boreal, bc.poly.boreal, west.boreal)
```

#### MPB `RasterStack`

```{r plot-mpb.western.boreal.raster.stack, fig.height=12, fig.width=12}
loadObjects(c("bcab.all.boreal.raster.stack", "west.boreal"), rdata.path)
colours <- brewer.pal(n = 9, name = "YlOrRd")
years <- substr(names(bcab.all.boreal.raster.stack), 2, 5)
last9 <- (length(years) - 8):length(years) # the last 9 years
subset <- last9[last9 > 0]

plot(bcab.all.boreal.raster.stack, subset, main = years, legend = FALSE, axes = FALSE,
     col = c("white", colours), addfun = function(x) plot(west.boreal, add = TRUE))
#legend("topright", legend = years[subset], fill = colours)

png(file.path(fig.path, "bcab.all.boreal.raster.stack.png"), type = "cairo", width = 2400, height = 1600)
plot(bcab.all.boreal.raster.stack, subset, main = years, cex.main = 3,
     legend = FALSE, axes = FALSE, col = c("white", colours),
     addfun = function(x) plot(west.boreal, add = TRUE))
#legend("topright", legend = years[subset], fill = colours)
dev.off()

rm(bcab.all.boreal.raster.stack, west.boreal)
```

#### MPB `RasterBrick` timeseries

```{r plot-mpb.western.boreal.time.series, fig.height=12, fig.width=12}
loadObjects(c("bcab.all.boreal.raster.brick", "west.boreal"), rdata.path)

# `spsample` needs planar coordinates, so need to reproject to latlong
crs.latlon <- CRS("+proj=longlat +datum=WGS84")
brick.latlon <- projectRaster(bcab.all.boreal.raster.brick, crs = crs.latlon)

# replace NAs with zeros (WHY??)
brick.latlon <- brick(lapply(1:nlayers(brick.latlon), function(x) {
  brick.latlon[[x]][is.na(brick.latlon[[x]])] <- 0
  return(brick.latlon[[x]])
}))
brick.latlon@title <- "MPB intensity"
brick.latlon <- writeRaster(brick.latlon, filename = file.path(rdata.path, "mpb_brick_latlon.grd"), overwrite = TRUE)

#brick.latlon <- brick(file.path(rdata.path, "mpb_brick_latlon.grd"))
years <- as.numeric(substr(names(bcab.all.boreal.raster.brick), 2, 5))
t.strt <- as.POSIXct(as.Date(paste(years, "-10-01", sep = "")))     ## why Oct 1?
t.stop <- as.POSIXct(as.Date(paste(years + 1, "-10-01", sep = ""))) ## why Oct 1?

# random sample of spatial points
sps <- spsample(west.boreal, 1, type = "random") %>% 
  spTransform(crs.latlon) %>%
  SpatialPointsDataFrame(data = data.frame(dat = 1))

# colour palette
colours <- brewer.pal(n = 9, name = "YlOrRd")

# `plotKML` timeseries
ts.kml <- new("RasterBrickTimeSeries", variable = "X", sampled = sps, rasters = brick.latlon,
              TimeSpan.begin = t.strt, TimeSpan.end = t.stop)
dims <- dim(brick.latlon)
#plotKML(ts.kml, colour_scale = c(rep("black",2), heat.colors(12)[12:1]),
#        pngwidth = dims[1], pngheight = dims[2], pngpointsize = 14)

# `rts` timeseries
ts.rts <- rts(brick.latlon, time = as.POSIXct(as.Date(t.strt)))
plot(ts.rts, col = c("white", colours)) # this is a *garbage* way to plot a TS

saveObjects(c("brick.latlon", "ts.kml", "ts.rts"), rdata.path)
rm(bcab.all.boreal.raster.brick, brick.latlon, ts.kml, ts.rts, west.boreal)
.cleanup()
```
